{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow._api.v2.data import Dataset\n",
    "from keras._tf_keras.keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.src.models import Sequential\n",
    "from keras.src.layers import Dense, Flatten, Conv2D, MaxPooling2D, Dropout\n",
    "from keras.src.callbacks import EarlyStopping\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, precision_score, recall_score, f1_score\n",
    "from keras.src.utils import to_categorical\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.src.utils import image_dataset_from_directory\n",
    "import json\n",
    "from keras.src.regularizers import L2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Percorsi ai dataset\n",
    "train_images_path = 'data/images_training_rev1/images_training_rev1'\n",
    "test_images_path = 'data/images_test_rev1/images_test_rev1'\n",
    "train_labels_path = 'solutions/training_solutions_rev1/training_solutions_rev1.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Percorsi ai dataset sul portatile\n",
    "train_images_path = 'C:/Users/AndreaBianchini/Downloads/galaxy-zoo-the-galaxy-challenge/images_training_rev1/images_training_rev1'\n",
    "test_images_path = 'C:/Users/AndreaBianchini/Downloads/galaxy-zoo-the-galaxy-challenge/images_test_rev1/images_test_rev1'\n",
    "train_labels_path = 'C:/Users/AndreaBianchini/Downloads/galaxy-zoo-the-galaxy-challenge/training_solutions_rev1/training_solutions_rev1.csv' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Caricamento delle etichette\n",
    "train_labels_df = pd.read_csv(train_labels_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funzione per creare il dataset tf.data\n",
    "\n",
    "#In sintesi:\n",
    "    #Carica l'immagine dal percorso specificato (img_path).\n",
    "    #Decodifica l'immagine come JPEG con 3 canali (RGB).\n",
    "    #Ridimensiona l'immagine a 64x64 pixel.\n",
    "    #Normalizza i valori dei pixel tra 0 e 1.\n",
    "    #Restituisce l'immagine preprocessata e l'array delle etichette.\n",
    "\n",
    "def load_image(img_path, label): #prende in input il path dell'immagine e l'etichetta associata(label)\n",
    "    img = tf.io.read_file(img_path) #memorizzo nella variabile 'img' il percorso dell'immagine come tensore grezzo di byte\n",
    "    img = tf.image.decode_jpeg(img, channels=3) #decodifica l'immagine jpeg nel tensore 'img' specificando che l'immagine ha 3 canali (RGB)\n",
    "    img = tf.image.resize(img, [128, 128]) #ridimensiona l'immagine in 64x64 pixel\n",
    "    img = img / 255.0  # Normalizzazione dei pixel dell'immagine per essere compresi tra 0 e 1 \n",
    "    return img, label #restituisco l'immagine preprocessata e l'etichetta associata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#In sintesi:\n",
    "    #Crea un dataset TensorFlow dai percorsi delle immagini (image_paths) e dalle etichette (labels).\n",
    "    #Applica la funzione load_image a ciascun elemento del dataset in parallelo.\n",
    "    #Mescola il dataset con un buffer di 1000 elementi.\n",
    "    #Raggruppa gli elementi del dataset in batch di dimensione 64.\n",
    "    #Precarica i dati per migliorare l'efficienza.\n",
    "    #Restituisce il dataset preprocessato.\n",
    "\n",
    "def create_dataset(image_paths, labels): #prende in input il path delle immagini e le etichette associate\n",
    "    dataset = Dataset.from_tensor_slices((image_paths, labels)) #crea un dataset tensorflow dai tensori 'image_paths' e 'labels' \n",
    "    #ed ogni elemento del dataset è una coppia\n",
    "    dataset = dataset.map(load_image, num_parallel_calls=tf.data.AUTOTUNE) #applica la funzione load_image a ogni elemento del dataset.\n",
    "    #tf.data.AUTOTUNE consente a tensorflow di determinare automaticamente il numero ottimale di thread di esecuzione per migliorare perf.\n",
    "    dataset = dataset.shuffle(buffer_size=1000).batch(64).prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "    #dataset.shuffle(buffer_size)=1000 --> mescola gli elementi del dataset con un buffer di 1000 elementi\n",
    "    #dataset.batch(64) --> raccoglie gli elementi del dataset in batch di dimensione 64\n",
    "    #dataset.prefetch(buffer_size=tf.data.AUTOTUNE) --> precarica i dati nel buffer per garantire che la GPU abbia sempre i dati pronti\n",
    "    #per l'addestramento, migliorando l'efficenza\n",
    "    return dataset #la funzione restituisce il dataset preprocessato\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creazione del DataFrame con i percorsi delle immagini e le etichette\n",
    "#Creo un elenco image_paths, contenente i percorsi completi delle immagini di training\n",
    "image_paths = [os.path.join(train_images_path, f\"{int(img_id)}.jpg\") for img_id in train_labels_df['GalaxyID']]\n",
    "#Estraggo le etichette associate alle immagini dal Dataframe del csv solutions training, escludendo la colonna del GalaxyID\n",
    "labels = train_labels_df.iloc[:, 1:].values #seleziono tutte le colonne tranne la prima e le converto in un array numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split del dataset in training e validation\n",
    "image_paths_train, image_paths_val, labels_train, labels_val = train_test_split(image_paths, labels, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creazione dei dataset tf.data\n",
    "train_dataset = create_dataset(image_paths_train, labels_train)\n",
    "val_dataset = create_dataset(image_paths_val, labels_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creazione del modello della rete neurale\n",
    "#Modello CNN (rete neurale convoluzionale)\n",
    "model = Sequential([\n",
    "#Spiegazione:\n",
    "#Kernel: Un kernel (o filtro) è una matrice 2D (in questo caso 3x3) che scorre sull'immagine di input e calcola il prodotto scalare tra il kernel e la regione dell'immagine coperta dal kernel.\n",
    "#Padding: Se non viene utilizzato il padding (cioè, il padding è 'valid'), la dimensione dell'output si riduce rispetto all'input. Con un kernel 3x3, ogni convoluzione riduce la dimensione dell'immagine di 2 (1 pixel da ogni lato). Quindi, l'immagine di dimensione 64x64 diventa 62x62.\n",
    "#Numero di Filtri: Qui specifichiamo che vogliamo 32 filtri, quindi otteniamo 32 feature maps. Ogni filtro è responsabile dell'estrazione di diverse caratteristiche dall'immagine di input (bordo, texture, ecc.).\n",
    "    #Conv2D Layer (32 filtri, kernel 3x3, ReLU):\n",
    "    #Input: immagine di dimensione (64, 64, 3), cioè 64x64 pixel con 3 canali colori.\n",
    "    #Output: Un set di 32 feature maps (mappe di caratteristiche), ciascuna di dimensioni (62, 62) ***Non ho ben capito***\n",
    "    #Funzione di attivazione: ReLU introduce non-linearità.\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(128, 128, 3)),\n",
    "    #MaxPooling2D Layer (pooling 2x2):\n",
    "    #Input: Le 32 feature maps di dimensioni (62, 62) dall'output del livello precedente (Conv2D).\n",
    "    #Output: 32 feature maps ridotte a dimensioni (31, 31) attraverso l'operazione di pooling.\n",
    "    #Operazione: Prende il massimo valore in ogni finestra 2x2 ***Non ho ben capito***\n",
    "    MaxPooling2D((2, 2)),\n",
    "    #Conv2D Layer (64 filtri, kernel 3x3, ReLU):\n",
    "    #Input: Le 32 feature maps di dimensioni (31, 31) (output precedente).\n",
    "    #Output: Un set di 64 feature maps, ciascuna di dimensioni (29, 29).\n",
    "    #Funzione di Attivazione: ReLU.\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    #MaxPooling2D Layer (pooling 2x2):\n",
    "    #Input: Le 64 feature maps di dimensioni (29, 29) (output precedente).\n",
    "    #Output: 64 feature maps ridotte a dimensioni (14, 14).\n",
    "    MaxPooling2D((2, 2)),\n",
    "    #Flatten Layer:\n",
    "    #Input: Le 64 feature maps di dimensioni (14, 14) (output precedente).\n",
    "    #Output: Un vettore unidimensionale (1D) di lunghezza 12544 (64 * 14 * 14).\n",
    "    Flatten(),\n",
    "    #Funzione: Disattiva casualmente il 50% dei neuroni durante l'addestramento per prevenire l'overfitting.\n",
    "    Dropout(0.5),\n",
    "    #Dense Layer (128 neuroni, ReLU):\n",
    "    #Input: Il vettore 1D di lunghezza 12544.\n",
    "    #Output: Un vettore 1D di lunghezza 128.\n",
    "    #Funzione di Attivazione: ReLU.\n",
    "    Dense(128, activation='relu'),\n",
    "    #Output Layer (37 neuroni, sigmoid):\n",
    "    #Input: Il vettore 1D di lunghezza 128.\n",
    "    #Output: Un vettore 1D di lunghezza 37, con valori tra 0 e 1.\n",
    "    #Funzione di Attivazione: Sigmoid (permette la regressione multilabel).\n",
    "    Dense(37, activation='sigmoid')  # Utilizziamo sigmoid per una regressione multilabel\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Callback per l'early stopping\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Addestramento del modello\n",
    "history = model.fit(train_dataset, epochs=20, validation_data=val_dataset, callbacks=[early_stopping])\n",
    "# Salvataggio del modello\n",
    "model.save('galaxy_model.keras')\n",
    "print(\"Modello salvato in 'galaxy_model.keras'\")\n",
    "# Salvataggio dello storico dell'allenamento\n",
    "with open('history.json', 'w') as f:\n",
    "    json.dump(history.history, f)\n",
    "print(\"Storico dell'allenamento salvato in 'history.json'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carica lo storico dell'allenamento\n",
    "with open('history.json', 'r') as f:\n",
    "    history = json.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting training & validation accuracy values\n",
    "plt.figure(figsize=(6, 4))\n",
    "\n",
    "# Sotto-grafico per l'accuratezza\n",
    "plt.plot(history['accuracy'], label='Train')\n",
    "plt.plot(history['val_accuracy'], label='Validation')\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(loc='upper left')\n",
    "\n",
    "plt.figure(figsize=(6, 4))\n",
    "\n",
    "# Sotto-grafico per la perdita\n",
    "plt.plot(history['loss'], label='Train')\n",
    "plt.plot(history['val_loss'], label='Validation')\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(loc='upper left')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Per caricarlo in futuro:\n",
    "model = tf.keras.models.load_model('galaxy_model.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Caricamento delle immagini di test\n",
    "test_files = os.listdir(test_images_path)\n",
    "test_image_paths = [os.path.join(test_images_path, file) for file in test_files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creazione del dataset tf.data per le immagini di test\n",
    "test_dataset = create_dataset(test_image_paths, labels=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predizione delle etichette per il test set\n",
    "predictions = model.predict(test_dataset, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creazione del DataFrame con le predizioni\n",
    "test_filenames = [os.path.basename(path) for path in test_image_paths]\n",
    "predictions_df = pd.DataFrame(predictions, columns=[f'Class{i}' for i in range(predictions.shape[1])])\n",
    "predictions_df.insert(0, 'GalaxyID', [int(f.split('.')[0]) for f in test_filenames])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salvataggio delle predizioni in un file CSV\n",
    "predictions_df.to_csv('galaxies_predictions.csv', index=False)\n",
    "\n",
    "print(\"Predizioni salvate in 'galaxies_predictions.csv'\")\n",
    "\n",
    "#Carico il mio test prediction\n",
    "test_predictions = pd.read_csv('galaxies_predictions.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Carico i benchmark\n",
    "#Benchmark con soli 1:\n",
    "benchmark_ones = pd.read_csv('benchmark/all_ones_benchmark/all_ones_benchmark.csv')\n",
    "#Benchmark con soli 0:\n",
    "benchmark_zeros = pd.read_csv('benchmark/all_zeros_benchmark/all_zeros_benchmark.csv')\n",
    "#Benchmark che valuta il pixel centrale:\n",
    "benchmark_central_pixel = pd.read_csv('benchmark/central_pixel_benchmark/central_pixel_benchmark.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Path sul portatile\n",
    "#Benchmark con soli 1:\n",
    "benchmark_ones = pd.read_csv('C:/Users/AndreaBianchini/Downloads/galaxy-zoo-the-galaxy-challenge/all_ones_benchmark/all_ones_benchmark.csv')\n",
    "#Benchmark con soli 0:\n",
    "benchmark_zeros = pd.read_csv('C:/Users/AndreaBianchini/Downloads/galaxy-zoo-the-galaxy-challenge/all_zeros_benchmark/all_zeros_benchmark.csv')\n",
    "#Benchmark che valuta il pixel centrale:\n",
    "benchmark_central_pixel = pd.read_csv('C:/Users/AndreaBianchini/Downloads/galaxy-zoo-the-galaxy-challenge/central_pixel_benchmark/central_pixel_benchmark.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funzione per calcolare l'accuratezza di un benchmark\n",
    "def calculate_accuracy(predictions, benchmark):\n",
    "    return np.mean(np.argmax(predictions.values[:, 1:], axis=1) == np.argmax(benchmark.values[:, 1:], axis=1))\n",
    "\n",
    "# Calcolo l'accuratezza paragonando le mie prediction ai benchmark\n",
    "accuracy_ones = calculate_accuracy(test_predictions, benchmark_ones)\n",
    "accuracy_zeros = calculate_accuracy(test_predictions, benchmark_zeros)\n",
    "accuracy_central_pixel = calculate_accuracy(test_predictions, benchmark_central_pixel)\n",
    "\n",
    "print(f'Accuracy with All Ones Benchmark: {accuracy_ones}')\n",
    "print(f'Accuracy with All Zeros Benchmark: {accuracy_zeros}')\n",
    "print(f'Accuracy with Central Pixel Benchmark: {accuracy_central_pixel}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# significa che il 62.38% delle predizioni totali del modello (sia positive che negative) corrispondono a quelle del benchmark Central Pixel.\n",
    "\n",
    "# Calcoli generali\n",
    "y_true = np.argmax(benchmark_central_pixel.values[:, 1:], axis=1)\n",
    "y_pred = np.argmax(test_predictions.values[:, 1:], axis=1)\n",
    "\n",
    "# Precision, Recall, F1 Score\n",
    "precision = precision_score(y_true, y_pred, average='weighted')\n",
    "f1 = f1_score(y_true, y_pred, average='weighted')\n",
    "\n",
    "#print(f'Precision: {precision}') #implica che quasi tutte le galassie che il tuo modello ha predetto come positive sono effettivamente positive secondo il benchmark Central Pixel.\n",
    "print(f'F1 Score: {f1}') # rappresenta un bilancio tra precisione e recall, suggerendo che il modello è abbastanza bilanciato ma potrebbe migliorare nel catturare tutte le istanze positive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "UFS12DL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
